{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROTO V1.0\n",
    "<div class='alert alert-success'>\n",
    "Ce petit notebook permet d'évaluer Abstract Torch sur un petit réseau. \n",
    "Pour cela, on créé AbstractNN, un petit réseau composé de 2 couches de convolution suivies de ReLU, d'un maxpool, puis de deux couches FC suivies également de ReLU. \n",
    "Pour l'entrainement uniquement, un softmax est appliqué en sortie de réseau\n",
    "</div>\n",
    "\n",
    "Dans la classe AbstractNN, la méthode forward de nn.Linear est surchargée de façon standard.\n",
    "C'est à dire que si l'on instancie model=AbstractNN(), model(x) applique forward à x comme dans n'importe quel réseau. \n",
    "\n",
    "AbstractNN possède une méthode abstract_forward() qui fait appelle à AbstractLinear et AbstractReLU. \n",
    "<div class='alert alert-info'>\n",
    "Le lecteur avisé notera que \n",
    "    model(x)=nn.softmax(model.abstract_forward(x_abstract)[0])\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../util')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from abstractModule import AbstractLinear as AL\n",
    "from abstractModule import AbstractReLU as AR\n",
    "from abstractModule import AbstractMaxpool2D as AM\n",
    "\n",
    "from custom_train import CustomTrainer as T\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import random_split\n",
    "from torch import optim\n",
    "import os\n",
    "\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on importe le dataset FashionMNIST normalisation et random split pour l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path ='dataset'\n",
    "\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean =[0.5], std =[0.2]),\n",
    "        #transforms.Resize((56,56))\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "dataset_train = datasets.FashionMNIST(root = path,transform = transform, download = True, train = True)\n",
    "dataset_test =datasets.FashionMNIST( root =path,transform=transform ,download = True, train = False)\n",
    "val =0.2\n",
    "len_data_train = len(dataset_train)\n",
    "train_size =int((1-val)*len_data_train)\n",
    "\n",
    "val_size = int(val*len_data_train)\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset_train, [train_size,val_size])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on génère notre classe AbstractNN et sa fameuse méthode abstrac_forward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class AbstractNN(nn.Module):\n",
    "    \n",
    "    def __init__(self,num_depth=1,device=torch.device(\"cpu\")):\n",
    "\n",
    "        super(AbstractNN,self).__init__()\n",
    "       \n",
    "      \n",
    "        self.num_depth = num_depth\n",
    "        self.device = device\n",
    "        self.conv1=nn.Conv2d(self.num_depth,16,3,device=self.device)\n",
    "        self.conv2=nn.Conv2d(16,32,3,device=self.device)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2,stride=2,padding=0)\n",
    "  \n",
    "\n",
    "       \n",
    "\n",
    "        self.fc1=nn.Sequential(nn.Flatten(),nn.Linear(4608,64,device=self.device))\n",
    "        self.fc2=nn.Sequential(nn.Flatten(),nn.Linear(64,10,device=self.device))\n",
    "        self.softMax =nn.Softmax()\n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=torch.relu(x)\n",
    "        x=self.conv2(x)\n",
    "        x=torch.relu(x)\n",
    "     \n",
    "        x=self.maxpool(x)\n",
    "     \n",
    "    \n",
    "        x=self.fc1(x)\n",
    "        x=torch.relu(x)\n",
    "        x=self.fc2(x)\n",
    "        x=torch.relu(x)\n",
    "        x= self.softMax(x)\n",
    "        return x\n",
    "    \n",
    "    def abstract_forward(self,x,add_symbol=False,device=torch.device(\"cpu\")):\n",
    "        self.device=device\n",
    "        \n",
    "        x_true = x\n",
    "        x_true = x_true[0].unsqueeze(0)\n",
    "\n",
    "        x,x_min,x_max,x_true = AL.abstract_conv2D(self.conv1,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = AR.abstract_relu_conv2D(x,x_min,x_max,x_true,add_symbol=add_symbol,device =self.device)\n",
    "     \n",
    "       \n",
    "        x,x_min,x_max,x_true = AL.abstract_conv2D(self.conv2,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = AR.abstract_relu_conv2D(x,x_min,x_max,x_true,add_symbol=add_symbol,device =self.device)\n",
    "        x,x_min,x_max ,x_true = AM.abstract_maxpool2D(self.maxpool,x,x_true,add_symbol=add_symbol,device=self.device)\n",
    "        x,x_min,x_max,x_true = AL.abstract_linear(self.fc1,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = AR.abstract_relu(x,x_min,x_max,x_true,add_symbol=add_symbol,device =self.device)\n",
    "      \n",
    "        x,x_min,x_max,x_true = AL.abstract_linear(self.fc2,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = AR.abstract_relu(x,x_min,x_max,x_true,add_symbol=add_symbol,device =self.device)\n",
    "       \n",
    "        \n",
    "        return x,x_min,x_max,x_true\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un petit script pour l'entrainement, disons 10 EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"model =AbstractNN(num_depth=1,device=torch.device('cpu'))\n",
    "\n",
    "num_epochs =10\n",
    "learning_rate=0.01\n",
    "batch_size = 128\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), betas=(0.9, 0.99))\n",
    "scheduler =  optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.98)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "TD= T(model=model,\n",
    "            device=device\n",
    "                            )\n",
    "model = TD.train_model(train_dataset,val_dataset,\n",
    "                        criterion=criterion,  \n",
    "                        batch_size= batch_size,\n",
    "                        optimizer=optimizer,\n",
    "                        scheduler=scheduler,\n",
    "                        num_epochs=num_epochs,\n",
    "                        learning_rate=learning_rate,\n",
    "                        resname='SimpleCNN',verbose=False)\n",
    "                        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=AbstractNN(num_depth=1,device=torch.device('cpu')    )\n",
    "model.load_state_dict(torch.load('dataset/FMNIST.pth'))\n",
    "device = torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "img, label = dataset_train[0]\n",
    "plt.imshow(img[0])\n",
    "print(f\"Label:{label}\")\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max= torch.max(img)\n",
    "min = torch.min(img)\n",
    "scale = max-min\n",
    "print(scale)\n",
    "\n",
    "from abstract import abstractTensor as AT\n",
    "\n",
    "x=AT(img,alpha =0.005*scale*torch.ones(28*28))\n",
    "x=x.abstract_tensor()\n",
    "x.shape\n",
    "x=x.to(device)\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "   result_1= model(x[0].unsqueeze(0))  \n",
    " \n",
    "   result,x_min,x_max,x_true=model.abstract_forward(x,add_symbol=False,device=torch.device('cpu'))\n",
    "\n",
    "print(f\"y_min       =  {x_min}\")\n",
    "print(f\"y_max       =  {x_max}\")\n",
    "print(f\"center Ztp  =  {result[0]}\")\n",
    "print(f\"y_true      =  {x_true[:]}\")\n",
    "print(f\"y_max-x_min =  {x_max-x_min}\")\n",
    "print(f\"Trash symbol=  {result[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_min       =  np.array(x_min)\n",
    "y_max       =  np.array(x_max)\n",
    "center_Ztp  =  np.expand_dims(np.array(result[0]),axis =1)\n",
    "y_true      =  np.expand_dims(np.array(x_true[:])[0],axis =1)\n",
    "y_max_minus_y_min =  np.array(x_max-x_min)\n",
    "Trash_symbol=  np.array(result[-1])\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x = np.arange(len(y_min))\n",
    "D =np.stack((y_min,y_max),axis=1)\n",
    "\n",
    "print(D.shape)\n",
    "print(center_Ztp.shape)\n",
    "print(y_true.shape)\n",
    "# plot:\n",
    "\n",
    "fig,ax = plt.subplots(1, 1, figsize=(8,4), tight_layout=True)\n",
    "ax.eventplot(D, orientation=\"vertical\", linewidth=1,color='blue',linelengths=0.3)\n",
    "ax.eventplot(y_true, orientation=\"vertical\", linewidth=0.50,color='green',linelengths=0.4)\n",
    "ax.eventplot(center_Ztp, orientation=\"vertical\", linewidth=1,color='red',linelengths=0.5)\n",
    "\n",
    "ax.set(xlim=(-0.5, 10),xticks=x,xticklabels=[\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag,\",\"Ankle boot\"],\n",
    "       ylim=(np.min(D)-1, np.max(D)+1))\n",
    "plt.ylabel(\"Value of the abstract domain\")\n",
    "plt.title(\"Dominance interval for the 10 classes of Fashion MNIST .\\n Abstract domain based on 100_000 lower weights of the first layer of the first fully connected layer of the model\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max= torch.max(img)\n",
    "min = torch.min(img)\n",
    "scale = max-min\n",
    "print(scale)\n",
    "\n",
    "from abstract import abstractTensor as AT\n",
    "\n",
    "x=AT(img,alpha =0.005*scale*torch.ones(28*28))\n",
    "x=x.abstract_tensor()\n",
    "x.shape\n",
    "x=x.to(device)\n",
    "print(x.shape)\n",
    "with torch.no_grad():\n",
    "   result_1= model(x[0].unsqueeze(0))  \n",
    " \n",
    "   result,x_min,x_max,x_true=model.abstract_forward(x,add_symbol=True,device=torch.device('cpu'))\n",
    "\n",
    "print(f\"y_min       =  {x_min}\")\n",
    "print(f\"y_max       =  {x_max}\")\n",
    "print(f\"center Ztp  =  {result[0]}\")\n",
    "print(f\"y_true      =  {x_true[:]}\")\n",
    "print(f\"y_max-x_min =  {x_max-x_min}\")\n",
    "print(f\"Trash symbol=  {result[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_min       =  np.array(x_min)\n",
    "y_max       =  np.array(x_max)\n",
    "center_Ztp  =  np.expand_dims(np.array(result[0]),axis =1)\n",
    "y_true      =  np.expand_dims(np.array(x_true[:])[0],axis =1)\n",
    "y_max_minus_y_min =  np.array(x_max-x_min)\n",
    "Trash_symbol=  np.array(result[-1])\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x = np.arange(len(y_min))\n",
    "D =np.stack((y_min,y_max),axis=1)\n",
    "\n",
    "print(D.shape)\n",
    "print(center_Ztp.shape)\n",
    "print(y_true.shape)\n",
    "# plot:\n",
    "\n",
    "fig,ax = plt.subplots(1, 1, figsize=(8,4), tight_layout=True)\n",
    "ax.eventplot(D, orientation=\"vertical\", linewidth=1,color='blue',linelengths=0.3)\n",
    "ax.eventplot(y_true, orientation=\"vertical\", linewidth=0.50,color='green',linelengths=0.4)\n",
    "ax.eventplot(center_Ztp, orientation=\"vertical\", linewidth=1,color='red',linelengths=0.5)\n",
    "\n",
    "ax.set(xlim=(0, 10),xticks=x,xticklabels=[\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag,\",\"Ankle boot\"],\n",
    "       ylim=(np.min(D)-1, np.max(D)+1))\n",
    "plt.ylabel(\"Value of the abstract domain\")\n",
    "plt.title(\"Dominance interval for the 10 classes of Fashion MNIST .\\n Abstract domain based on 100_000 lower weights of the first layer of the first fully connected layer of the model\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici le premier affichage de relevance calculé par AbstractTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value=torch.argmax(result[0])\n",
    "print(value)\n",
    "concat= torch.abs(result[1:785,value])\n",
    "print(concat.size())\n",
    "\n",
    "concat = concat.reshape(28,28)\n",
    "plt.imshow(torch.abs(concat.cpu()).numpy(), cmap='viridis')\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
