{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch   \n",
    "import torch.nn as nn\n",
    "import copy\n",
    "from torch.functional import F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AbstractTorch\n",
    "Ceci est un prototype de moteur d'évaluation s'appuyant sur Torch. L'idée est de surcharger nn.Linear avec des méthodes hybrides, gérant un flux abstrait pour l'évaluation et un flux concret. La simultanéité des deux flux permet d'oberver la position du centre du zonotope par rapport à la valeur réelle de la sortie de la fonction. \n",
    "Ce moteur est moins précis que Saimple car il ne génère pas de nouveaux symboles mais additionne les approximations dans un symbole poubelle. \n",
    "\n",
    "L'implémentation du modèle abstrait comporte une quantité fixe de symboles qui sont gérés comme des épaisseurs de batch. La dernière épaisseur de batch correspond au symbole poubelle, les opération linéaires sont opérées pour cette épaisseur par la valeur absolu de la matrice des poids. \n",
    "\n",
    "Pour l'instant sont implémentées les classes conv2D, Linear , et ReLU. \n",
    "        #TODO implémenter maxpool2D, ... \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée est de tirer profit de la classe nn.Module de Torch en la surchargeant avec des méthodes mixes (flux concret et abstrait). On tire profit de la structure de base\n",
    "de la méthode forward. Au lieu de considérer un batch, on considère une entrée en dimension 0 avec dans les dimensions habituelles du batch des couches de symbole. Une couche (un épaisseur de batch) représente\n",
    "un symbole abstrait. La dernière couche correspond au symbole poubelle. \n",
    "\n",
    "\n",
    "La couche 0 représente le centre du zonotope\n",
    "Les couches suivantes représentent les symboles. Elles sont calculées pour les opération linéaires (Linear et Conv2D) par \n",
    "$$\\textbf{W}(x_\\epsilon)+\\textbf{b}-(\\textbf{W}(0)+\\textbf{b})$$\n",
    "    x[1:]=lin(x_epsilon)-lin(torch.zeros_like(x_epsilon))\n",
    "\n",
    "La derniere couche (bruit poubelle) est calculée par\n",
    "\n",
    "$$\\textbf{|W|}(x_\\epsilon)+\\textbf{b}-(\\textbf{|W|}(0)+\\textbf{b})$$\n",
    "\n",
    "\n",
    "Pour implémenter le tenseur linéaire représentant la valeur absolue, on duplique la couche lin ou conv et on applique la valeur absolue à la matrice de poids. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode abstractTensor permet, à partir d'un tenseur d'origine, de générer un tenseur abstrait. \n",
    "\n",
    "Cette méthode doit être largement enrichie en classe, avec différentes méthodes telles que \n",
    "    add_noise\n",
    "    mul_noise\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstractTensor(tensor: torch.Tensor, alpha : list[float]):\n",
    "    assert len(alpha)==len(tensor.flatten()), \"The length of alpha should be equal to the length of the flatten tensor\"\n",
    "    print(tensor.shape)\n",
    "    \n",
    "    flatten_tensor  = tensor.flatten()\n",
    "    abstract_tensor=[]\n",
    "    abstract_tensor.append(tensor)\n",
    "    for i in range(1,len(flatten_tensor)+1):\n",
    "        abstract_tensor_layer = torch.zeros_like(flatten_tensor)\n",
    "        abstract_tensor_layer[i-1]=alpha[i-1]\n",
    "        abstract_tensor_layer = abstract_tensor_layer.reshape(tensor.shape)\n",
    "        abstract_tensor.append(abstract_tensor_layer)\n",
    "    \n",
    "    abstract_tensor.append(torch.zeros_like(tensor))\n",
    "    abstract_tensor= torch.stack(abstract_tensor)\n",
    "\n",
    "    \n",
    "    return abstract_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractNN(nn.Module):\n",
    "    \n",
    "    def __init__(self,num_symbols: int,num_depth=1,device=torch.device(\"cpu\")):\n",
    "\n",
    "        super(AbstractNN,self).__init__()\n",
    "        num_symbols = num_symbols +2\n",
    "        self.num_symbols = num_symbols\n",
    "        self.num_depth = num_depth\n",
    "        self.device = device\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod    \n",
    "    def abstract_linear(in_features:int,out_features:int,x,x_true,device=torch.device(\"cpu\")):\n",
    "        x =x.unsqueeze(1).to(device)\n",
    "        x_true=x_true.to(device)\n",
    "        lin = nn.Sequential(nn.Flatten(),\n",
    "                            nn.Linear(in_features=in_features, out_features=out_features,device=device))\n",
    "        lin_abs = copy.deepcopy(lin).to(device)\n",
    "        lin_abs[1].weight.data =torch.abs(lin[1].weight.data)\n",
    "     \n",
    "        \n",
    "        x_value = x[0].unsqueeze(1)\n",
    "        x_epsilon= x[1:-1].unsqueeze(1)\n",
    "        x_noise =x[-1].unsqueeze(1)\n",
    "       \n",
    "        x=lin(x)    \n",
    "        x_true = lin(x_true)\n",
    "        x[0]=lin(x_value)\n",
    "        x[1:-1]=lin(x_epsilon)-lin(torch.zeros_like(x_epsilon))\n",
    "        x[-1]=lin_abs(x_noise)-lin_abs(torch.zeros_like(x_noise))\n",
    "        x_min = x[0] - torch.sum(torch.abs(x[1:]),dim=0)\n",
    "        x_max = x[0] + torch.sum(torch.abs(x[1:]),dim=0)\n",
    "        print(x_min.type())\n",
    "        return x,x_min,x_max,x_true\n",
    "    \n",
    "    @staticmethod\n",
    "    def abstract_conv2D(in_channels:int,out_channels:int,kernel_size:int,x,x_true,device=torch.device(\"cpu\")):\n",
    "        x=x.to(device)\n",
    "        x_true = x_true.to(device)\n",
    "        conv = nn.Conv2d(in_channels=in_channels,out_channels=out_channels,kernel_size=kernel_size,device=device)\n",
    "      \n",
    "        conv_abs = copy.deepcopy(conv).to(device)\n",
    "        conv_abs.weight.data = torch.abs(conv.weight.data)\n",
    "     \n",
    "       \n",
    "        x_value = x[0]\n",
    "        x_epsilon= x[1:-1]\n",
    "        x_noise = x[-1]\n",
    "        x=conv(x)\n",
    "        x[0]=conv(x_value)\n",
    "        x_true = conv(x_true)\n",
    "        x[1:-1]=conv(x_epsilon)-conv(torch.zeros_like(x_epsilon).to(device))\n",
    "        x[-1]=conv_abs(x_noise)-conv_abs(torch.zeros_like(x_noise).to(device))\n",
    "        x_min = x[0] - torch.sum(torch.abs(x[1:]),dim=0)\n",
    "        x_max = x[0] + torch.sum(torch.abs(x[1:]),dim=0)\n",
    "        \n",
    "        return x,x_min,x_max,x_true\n",
    "    \n",
    "    @staticmethod\n",
    "    def abstract_relu_conv2D(x,x_min,x_max,x_true,num_symbols:int,add_symbol=False,device=torch.device(\"cpu\")):\n",
    "        num_symbols = len(x)\n",
    "        sgn_min = torch.sign(x_min)\n",
    "        sgn_max = torch.sign(x_max)\n",
    "        sgn = sgn_min+sgn_max\n",
    "        p = x_max/(torch.abs(x_max)+torch.abs(x_min))\n",
    "        q = x_max*(1-p)/2\n",
    "        d = torch.abs(q)\n",
    "        x_true  = nn.ReLU()(x_true)\n",
    "        copy_x_for_approx = x\n",
    "        mask_p = (sgn==0)*1\n",
    "        mask_1 =(sgn==2)*1 + (sgn==1)*1\n",
    "        mask_p = mask_p.unsqueeze(0).expand(num_symbols,-1,-1,-1)\n",
    "        mask_1 = mask_1.unsqueeze(0).expand(num_symbols,-1,-1,-1)\n",
    "        \n",
    "        #approximation of the center 0, (p*x+q) or the value itself \n",
    "        copy_x_for_approx[0]= mask_p[0]*(p*copy_x_for_approx[0]+q)+mask_1[0]*copy_x_for_approx[0]\n",
    "        \n",
    "        #update of the epsilon\n",
    "        copy_x_for_approx[1:-1]=p*mask_p[1:-1]*copy_x_for_approx[1:-1] + mask_1[1:-1]*copy_x_for_approx[1:-1]\n",
    "\n",
    "        #update of the noise symbol -> projection 0, |W|*espilon_noise or new noise if new linear approximation\n",
    "        copy_x_for_approx[-1]=d*mask_p[-1] +copy_x_for_approx[-1]*mask_p[-1] +mask_1[-1]*copy_x_for_approx[-1]\n",
    "\n",
    "        x=copy_x_for_approx\n",
    "        \n",
    "        x_min = x[0] - torch.sum(torch.abs(x[1:]),dim=0)\n",
    "        x_max = x[0] + torch.sum(torch.abs(x[1:]),dim=0)\n",
    "        \n",
    "        if add_symbol:\n",
    "            \"\"\"\n",
    "            new_symbols_indexes =torch.where(x[-1]!=0)\n",
    "\n",
    "\n",
    "            for index,value in enumerate(new_symbols_indexes[0]):\n",
    "            \n",
    "            \n",
    "                x =torch.cat((x,x[-1].unsqueeze(0)),dim=0)\n",
    "                \n",
    "                x[-2]=torch.zeros_like(x[-2])\n",
    "                \n",
    "                x[-2][value]=x[-1][value]\n",
    "            x[-1]=torch.zeros_like(x[-1])\n",
    "            \"\"\"\n",
    "                        \n",
    "            new_eps =torch.where(x[-1]!=0)[0].to(device)\n",
    "            index = torch.arange(len(new_eps)).to(device)\n",
    "            new_eps_batch_shape = x[-1].expand(len(new_eps)+1,-1,-1,-1).shape\n",
    "            new_eps_batch = torch.zeros(new_eps_batch_shape).to(device)\n",
    "            new_eps_batch[index,new_eps]=x[-1][new_eps]\n",
    "\n",
    "            x=x[:-1]\n",
    "\n",
    "            x = torch.cat((x,new_eps_batch),dim=0)            \n",
    "\n",
    "        return x,x_min,x_max,x_true\n",
    "    \n",
    "    @staticmethod\n",
    "    def abstract_relu(x,x_min,x_max,x_true, num_symbols:int,add_symbol=False,device=torch.device(\"cpu\")):\n",
    "        num_symbols = len(x)\n",
    "        if add_symbol:\n",
    "            num_symbols = len(x)\n",
    "        sgn_min = torch.sign(x_min)\n",
    "        sgn_max = torch.sign(x_max)\n",
    "        sgn = sgn_min+sgn_max\n",
    "        p = x_max/(torch.abs(x_max)+torch.abs(x_min))\n",
    "        q = x_max*(1-p)/2\n",
    "        d = torch.abs(q)\n",
    "        x_true  = nn.ReLU()(x_true)\n",
    "        copy_x_for_approx = x\n",
    "\n",
    "        #mask for values that will be approximated by the linear approximation\n",
    "        mask_p = (sgn==0)*1\n",
    "        #mask for the values for those the output is the same as the input (y=x)\n",
    "        mask_1 =(sgn==2)*1+ (sgn==1)*1\n",
    "        #expand the mask to the number of symbols\n",
    "        mask_p = mask_p.unsqueeze(0).expand(num_symbols,-1)\n",
    "        mask_1 = mask_1.unsqueeze(0).expand(num_symbols,-1)\n",
    "        #approximation of the center  \n",
    "        copy_x_for_approx[0]= mask_p[0]*(p*copy_x_for_approx[0]+q)+mask_1[0]*copy_x_for_approx[0]\n",
    "        #uptade of the epsilon\n",
    "        copy_x_for_approx[1:-1]=p*mask_p[1:-1]*copy_x_for_approx[1:-1] + mask_1[1:-1]*copy_x_for_approx[1:-1]\n",
    "        #update of the noise symbol -> projection 0, |W|*espilon_noise or new noise if new linear approximation\n",
    "        copy_x_for_approx[-1]=d*mask_p[-1] +copy_x_for_approx[-1]*mask_p[-1] + mask_1[-1]*copy_x_for_approx[-1]\n",
    "        x=copy_x_for_approx\n",
    "\n",
    "        x_min = x[0] - torch.sum(torch.abs(x[1:]),dim=0)\n",
    "        x_max = x[0] + torch.sum(torch.abs(x[1:]),dim=0)\n",
    "        \n",
    "        if add_symbol:\n",
    "            \"\"\"\n",
    "            new_symbols_indexes =torch.where(x[-1]!=0)\n",
    "\n",
    "\n",
    "            for index,value in enumerate(new_symbols_indexes[0]):\n",
    "            \n",
    "            \n",
    "                x =torch.cat((x,x[-1].unsqueeze(0)),dim=0)\n",
    "                \n",
    "                x[-2]=torch.zeros_like(x[-2])\n",
    "                \n",
    "                x[-2][value]=x[-1][value]\n",
    "            x[-1]=torch.zeros_like(x[-1])\n",
    "            \n",
    "            \"\"\"\n",
    "            new_eps =torch.where(x[-1]!=0)[0].to(device)\n",
    "            \n",
    "            index = torch.arange(len(new_eps)).to(device)\n",
    "            new_eps_batch_shape = x[-1].expand(len(new_eps)+1,-1).shape\n",
    "            new_eps_batch = torch.zeros(new_eps_batch_shape).to(device)\n",
    "            new_eps_batch[index,new_eps]=x[-1][new_eps]\n",
    "\n",
    "            x=x[:-1]\n",
    "\n",
    "            x = torch.cat((x,new_eps_batch),dim=0)\n",
    "\n",
    "        return x,x_min,x_max,x_true\n",
    "\n",
    "\n",
    "    def forward(self,x,add_symbol=False):\n",
    "\n",
    "        \n",
    "        x_true = x\n",
    "        x_true = x_true[0].unsqueeze(0)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "        x,x_min,x_max,x_true = self.abstract_conv2D(self.num_depth,16,3,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = self.abstract_relu_conv2D(x,x_min,x_max,x_true,self.num_symbols,add_symbol=add_symbol,device =self.device)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "       \n",
    "        x,x_min,x_max,x_true = self.abstract_conv2D(16,16,3,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = self.abstract_relu_conv2D(x,x_min,x_max,x_true,self.num_symbols,add_symbol=add_symbol,device =self.device)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "        x,x_min,x_max,x_true = self.abstract_conv2D(16,32,3,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = self.abstract_relu_conv2D(x,x_min,x_max,x_true,self.num_symbols,add_symbol=add_symbol,device =self.device)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "        x,x_min,x_max,x_true = self.abstract_conv2D(32,32,3,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = self.abstract_relu_conv2D(x,x_min,x_max,x_true,self.num_symbols,add_symbol=add_symbol,device =self.device)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "        x,x_min,x_max,x_true = self.abstract_linear(51200,6272,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = self.abstract_relu(x,x_min,x_max,x_true,self.num_symbols,add_symbol=add_symbol,device =self.device)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "        x,x_min,x_max,x_true = self.abstract_linear(6272,6272,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = self.abstract_relu(x,x_min,x_max,x_true,self.num_symbols,add_symbol=add_symbol,device =self.device)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "        x,x_min,x_max,x_true = self.abstract_linear(6272,6272,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = self.abstract_relu(x,x_min,x_max,x_true,self.num_symbols,add_symbol=add_symbol,device =self.device)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "        x,x_min,x_max,x_true = self.abstract_linear(6272,6272,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = self.abstract_relu(x,x_min,x_max,x_true,self.num_symbols,add_symbol=add_symbol,device =self.device)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "        x,x_min,x_max,x_true = self.abstract_linear(6272,512,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = self.abstract_relu(x,x_min,x_max,x_true,self.num_symbols,add_symbol=add_symbol,device =self.device)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "        x,x_min,x_max,x_true = self.abstract_linear(512,256,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = self.abstract_relu(x,x_min,x_max,x_true,self.num_symbols,add_symbol=add_symbol,device =self.device)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "\n",
    "        x,x_min,x_max,x_true = self.abstract_linear(256,8,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = self.abstract_relu(x,x_min,x_max,x_true,self.num_symbols,add_symbol=add_symbol,device =self.device)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "        return x,x_min,x_max,x_true\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on évalue un modèle généré aléatoirement, composé de 4 couches de convolution et de 5 couches linéaires, chacunes avec une fonction d'activation ReLU\n",
    "L'évaluation se fait sur un tenseur [54,54] généré aléatoirement, qui peut correspondre à une image par exemple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7643)\n"
     ]
    }
   ],
   "source": [
    "#!PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0\n",
    "device =torch.device('cpu')\n",
    "tensor = torch.randn(48,48)\n",
    "print(torch.max(tensor.flatten()  ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 48])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "alpha = 0.00070*torch.ones_like(tensor.flatten())\n",
    "abstract_tensor = abstractTensor(tensor,alpha).float()\n",
    "model = AbstractNN(48*48,device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract_tensor.shape= torch.Size([2306, 48, 48])\n",
      "abstract_tensor.type= torch.FloatTensor\n",
      "AbstractNN()\n",
      "lenx:2306\n",
      "lenx:2366\n",
      "lenx:2437\n",
      "lenx:2530\n",
      "lenx:2656\n",
      "torch.FloatTensor\n",
      "lenx:2762\n",
      "torch.FloatTensor\n",
      "lenx:2840\n",
      "torch.FloatTensor\n",
      "lenx:2902\n",
      "torch.FloatTensor\n",
      "lenx:2925\n",
      "torch.FloatTensor\n",
      "lenx:2926\n",
      "torch.FloatTensor\n",
      "lenx:2926\n",
      "torch.FloatTensor\n",
      "lenx:2926\n",
      "y_min       =  tensor([-0.0000, 0.0121, -0.0000, 0.0353, -0.0000, 0.0530, -0.0000, 0.0660])\n",
      "y_max       =  tensor([0.0000, 0.0121, 0.0000, 0.0353, 0.0000, 0.0530, 0.0000, 0.0660])\n",
      "center Ztp  =  tensor([-0.0000, 0.0121, -0.0000, 0.0353, -0.0000, 0.0530, -0.0000, 0.0660])\n",
      "y_true      =  tensor([[0.0000, 0.0121, 0.0000, 0.0353, 0.0000, 0.0530, 0.0000, 0.0660]])\n",
      "y_max-x_min =  tensor([0.0000e+00, 7.4618e-06, 0.0000e+00, 6.3106e-06, 0.0000e+00, 6.2436e-06,\n",
      "        0.0000e+00, 5.4240e-06])\n",
      "Trash symbol=  tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"abstract_tensor.shape= {abstract_tensor.shape}\")\n",
    "abstract_tensor = abstract_tensor.to(device)\n",
    "print(f\"abstract_tensor.type= {abstract_tensor.type()}\")\n",
    "\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "\n",
    "with torch.no_grad():\n",
    " \n",
    "   result,x_min,x_max,x_true=model(abstract_tensor.unsqueeze(1),add_symbol=True)\n",
    "\n",
    "\n",
    "print(f\"y_min       =  {x_min}\")\n",
    "print(f\"y_max       =  {x_max}\")\n",
    "print(f\"center Ztp  =  {result[0]}\")\n",
    "print(f\"y_true      =  {x_true[:]}\")\n",
    "print(f\"y_max-x_min =  {x_max-x_min}\")\n",
    "print(f\"Trash symbol=  {result[-1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2926, 8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results =result.to(\"cpu\").numpy()\n",
    "results = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.450581e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.117587e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.725290e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.725290e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.725290e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.450581e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.313226e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.725290e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.725290e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.725290e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.450581e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.490116e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.862645e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.862645e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.862645e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.725290e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.725290e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.235174e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.725290e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.725290e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.450581e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.450581e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.117587e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.450581e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.490116e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.303852e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.117587e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.117587e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.862645e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.725290e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.725290e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.725290e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.725290e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.450581e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.450581e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.117587e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.450581e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2923</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.117587e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.490116e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.862645e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.607703e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.235174e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.235174e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.725290e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0             1    2             3    4             5    6  \\\n",
       "2911  0.0  7.450581e-09  0.0  1.117587e-08  0.0 -3.725290e-09  0.0   \n",
       "2912  0.0  0.000000e+00  0.0  3.725290e-09  0.0  0.000000e+00  0.0   \n",
       "2913  0.0  9.313226e-09  0.0  0.000000e+00  0.0 -3.725290e-09  0.0   \n",
       "2914  0.0  0.000000e+00  0.0 -3.725290e-09  0.0  7.450581e-09  0.0   \n",
       "2915  0.0 -1.862645e-09  0.0 -1.862645e-08  0.0  0.000000e+00  0.0   \n",
       "2916  0.0  0.000000e+00  0.0 -3.725290e-09  0.0  0.000000e+00  0.0   \n",
       "2917  0.0  2.235174e-08  0.0  3.725290e-09  0.0 -3.725290e-09  0.0   \n",
       "2918  0.0  7.450581e-09  0.0  1.117587e-08  0.0  7.450581e-09  0.0   \n",
       "2919  0.0  1.303852e-08  0.0  1.117587e-08  0.0  1.117587e-08  0.0   \n",
       "2920  0.0  1.862645e-09  0.0 -3.725290e-09  0.0 -3.725290e-09  0.0   \n",
       "2921  0.0 -3.725290e-09  0.0  0.000000e+00  0.0  0.000000e+00  0.0   \n",
       "2922  0.0 -7.450581e-09  0.0  1.117587e-08  0.0  0.000000e+00  0.0   \n",
       "2923  0.0 -1.117587e-08  0.0 -1.490116e-08  0.0  1.490116e-08  0.0   \n",
       "2924  0.0  2.607703e-08  0.0 -2.235174e-08  0.0 -2.235174e-08  0.0   \n",
       "2925  0.0  0.000000e+00  0.0  0.000000e+00  0.0  0.000000e+00  0.0   \n",
       "\n",
       "                 7  \n",
       "2911  3.725290e-09  \n",
       "2912  7.450581e-09  \n",
       "2913  3.725290e-09  \n",
       "2914  1.490116e-08  \n",
       "2915 -1.862645e-08  \n",
       "2916 -3.725290e-09  \n",
       "2917 -7.450581e-09  \n",
       "2918  1.490116e-08  \n",
       "2919  0.000000e+00  \n",
       "2920  3.725290e-09  \n",
       "2921 -7.450581e-09  \n",
       "2922  7.450581e-09  \n",
       "2923 -1.862645e-08  \n",
       "2924  3.725290e-09  \n",
       "2925  0.000000e+00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on évalue un modèle fictif, l'entrée est une image de 26 sur 26 par 3 épaisseur,avec un symbole associé avec chaque dimension d'entrée (3*26*26)\n",
    "Attention, la dimension de la première couche linéaire doit s'accorder, le code vous renvoiera une erreur (10368 au lieu de 67712)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.2300)\n",
      "torch.Size([3, 26, 26])\n",
      "abstract_tensor.shape= torch.Size([2030, 3, 26, 26])\n",
      "lenx:2030\n",
      "lenx:2030\n",
      "lenx:2030\n",
      "lenx:2030\n",
      "lenx:2030\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2030x10368 and 51200x6272)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 11\u001b[0m    result,x_min,x_max,x_true\u001b[38;5;241m=\u001b[39mmodel(abstract_tensor)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_min       =  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_min\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_max       =  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_max\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ResearchEnv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ResearchEnv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 201\u001b[0m, in \u001b[0;36mAbstractNN.forward\u001b[0;34m(self, x, add_symbol)\u001b[0m\n\u001b[1;32m    199\u001b[0m x,x_min,x_max,x_true \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mabstract_relu_conv2D(x,x_min,x_max,x_true,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_symbols,add_symbol\u001b[38;5;241m=\u001b[39madd_symbol,device \u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlenx:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 201\u001b[0m x,x_min,x_max,x_true \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mabstract_linear(\u001b[38;5;241m51200\u001b[39m,\u001b[38;5;241m6272\u001b[39m,x,x_true,device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    202\u001b[0m x,x_min,x_max,x_true \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mabstract_relu(x,x_min,x_max,x_true,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_symbols,add_symbol\u001b[38;5;241m=\u001b[39madd_symbol,device \u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlenx:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 29\u001b[0m, in \u001b[0;36mAbstractNN.abstract_linear\u001b[0;34m(in_features, out_features, x, x_true, device)\u001b[0m\n\u001b[1;32m     26\u001b[0m x_epsilon\u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     27\u001b[0m x_noise \u001b[38;5;241m=\u001b[39mx[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m x\u001b[38;5;241m=\u001b[39mlin(x)    \n\u001b[1;32m     30\u001b[0m x_true \u001b[38;5;241m=\u001b[39m lin(x_true)\n\u001b[1;32m     31\u001b[0m x[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m=\u001b[39mlin(x_value)\n",
      "File \u001b[0;32m~/miniconda3/envs/ResearchEnv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ResearchEnv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ResearchEnv/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/ResearchEnv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ResearchEnv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ResearchEnv/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2030x10368 and 51200x6272)"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor = torch.randn(3,26,26)\n",
    "print(torch.max(tensor.flatten()  ))\n",
    "alpha = 0.000005*torch.ones_like(tensor.flatten())\n",
    "abstract_tensor = abstractTensor(tensor,alpha)\n",
    "print(f\"abstract_tensor.shape= {abstract_tensor.shape}\")\n",
    "model = AbstractNN(26*26*3,num_depth=3)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    " \n",
    "   result,x_min,x_max,x_true=model(abstract_tensor)\n",
    "\n",
    "\n",
    "print(f\"y_min       =  {x_min}\")\n",
    "print(f\"y_max       =  {x_max}\")\n",
    "print(f\"center Ztp  =  {result[0]}\")\n",
    "print(f\"y_true      =  {x_true[:]}\")\n",
    "print(f\"y_max-x_min =  {x_max-x_min}\")\n",
    "print(f\"Trash symbol=  {result[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "device =torch.device('mps')\n",
    "tensor = torch.randn(2,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2963)\n",
      "torch.Size([2, 2])\n",
      "torch.FloatTensor\n",
      "result = tensor([[-0.5611, -0.6019, -1.3127,  0.4239,  0.5597],\n",
      "        [-0.2410, -0.2443, -0.2251,  0.1972,  0.2159],\n",
      "        [ 0.0670, -0.1541, -0.1763, -0.0461,  0.0528],\n",
      "        [ 0.1253, -0.1288,  0.1929, -0.0029,  0.0682],\n",
      "        [-0.1605, -0.1294, -0.1256,  0.1114,  0.1824],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]], grad_fn=<CopySlices>)\n",
      "result = tensor([[ 4.5138e-04,  1.1391e-03, -0.0000e+00,  4.2393e-01,  5.5974e-01],\n",
      "        [-6.6451e-03, -1.0174e-02,  0.0000e+00,  1.9718e-01,  2.1587e-01],\n",
      "        [ 1.8461e-03, -6.4185e-03,  0.0000e+00, -4.6076e-02,  5.2821e-02],\n",
      "        [ 3.4554e-03, -5.3646e-03,  0.0000e+00, -2.8602e-03,  6.8199e-02],\n",
      "        [-4.4260e-03, -5.3901e-03,  0.0000e+00,  1.1136e-01,  1.8239e-01],\n",
      "        [ 1.5921e-02,  2.6208e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       grad_fn=<CopySlices>)\n",
      "y_true = tensor([[0.0000, 0.0000, 0.0000, 0.4239, 0.5597]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.max(tensor.flatten()  ))\n",
    "alpha = 0.5*torch.ones_like(tensor.flatten())\n",
    "abstract_tensor = abstractTensor(tensor,alpha).float()\n",
    "result,x_min,x_max,x_true = AbstractNN.abstract_linear(4,5,abstract_tensor,abstract_tensor[0].unsqueeze(0))\n",
    "print(f\"result = {result}\")\n",
    "result,x_min,x_max,x_true = AbstractNN.abstract_relu(result,x_min,x_max,x_true,6,add_symbol=False)\n",
    "print(f\"result = {result}\")\n",
    "print(f\"y_true = {x_true}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abstractModule import AbstractNN\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AbstractNN(device=torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 48])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn(48,48)\n",
    "alpha = 0.0005*torch.ones_like(tensor.flatten())\n",
    "abstract_tensor = abstractTensor(tensor,alpha).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenx:2306\n",
      "x.shape=torch.Size([2306, 1, 48, 48])\n",
      "lenx:2338\n",
      "x.shape=torch.Size([2338, 16, 46, 46])\n",
      "lenx:2391\n",
      "x.shape=torch.Size([2391, 16, 44, 44])\n",
      "lenx:2514\n",
      "x.shape=torch.Size([2514, 32, 42, 42])\n",
      "lenx:2585\n",
      "torch.FloatTensor\n",
      "lenx:2619\n",
      "torch.FloatTensor\n",
      "lenx:2660\n",
      "torch.FloatTensor\n",
      "lenx:2686\n",
      "torch.FloatTensor\n",
      "lenx:2693\n",
      "torch.FloatTensor\n",
      "lenx:2694\n",
      "torch.FloatTensor\n",
      "lenx:2694\n",
      "torch.FloatTensor\n",
      "lenx:2694\n",
      "y_min       =  tensor([0.0165, -0.0000, -0.0000, 0.0078, -0.0000, 0.0807, 0.0476, 0.0064])\n",
      "y_max       =  tensor([0.0165, 0.0000, 0.0000, 0.0078, 0.0000, 0.0807, 0.0476, 0.0064])\n",
      "center Ztp  =  tensor([0.0165, -0.0000, -0.0000, 0.0078, -0.0000, 0.0807, 0.0476, 0.0064])\n",
      "y_true      =  tensor([[0.0165, 0.0000, 0.0000, 0.0078, 0.0000, 0.0807, 0.0476, 0.0064]])\n",
      "y_max-x_min =  tensor([1.7695e-06, 0.0000e+00, 0.0000e+00, 2.7847e-06, 0.0000e+00, 6.8545e-07,\n",
      "        8.7172e-07, 2.0396e-06])\n",
      "Trash symbol=  tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    " \n",
    "   result,x_min,x_max,x_true=model(abstract_tensor.unsqueeze(1),add_symbol=True)\n",
    "\n",
    "\n",
    "print(f\"y_min       =  {x_min}\")\n",
    "print(f\"y_max       =  {x_max}\")\n",
    "print(f\"center Ztp  =  {result[0]}\")\n",
    "print(f\"y_true      =  {x_true[:]}\")\n",
    "print(f\"y_max-x_min =  {x_max-x_min}\")\n",
    "print(f\"Trash symbol=  {result[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenx:2306\n",
      "x.shape=torch.Size([2306, 1, 48, 48])\n",
      "lenx:2306\n",
      "x.shape=torch.Size([2306, 16, 46, 46])\n",
      "lenx:2306\n",
      "x.shape=torch.Size([2306, 16, 44, 44])\n",
      "lenx:2306\n",
      "x.shape=torch.Size([2306, 32, 42, 42])\n",
      "lenx:2306\n",
      "torch.FloatTensor\n",
      "lenx:2306\n",
      "torch.FloatTensor\n",
      "lenx:2306\n",
      "torch.FloatTensor\n",
      "lenx:2306\n",
      "torch.FloatTensor\n",
      "lenx:2306\n",
      "torch.FloatTensor\n",
      "lenx:2306\n",
      "torch.FloatTensor\n",
      "lenx:2306\n",
      "torch.FloatTensor\n",
      "lenx:2306\n",
      "y_min       =  tensor([-106318.3750, -119134.2578, -112783.0859, -116636.6094, -114800.7812,\n",
      "        -106218.4219, -108863.0859, -112458.7422])\n",
      "y_max       =  tensor([157195.1250, 175966.7656, 167548.6250, 175093.3906, 169235.3750,\n",
      "        162401.4844, 162499.5625, 165079.4531])\n",
      "center Ztp  =  tensor([25438.3730, 28416.2559, 27382.7715, 29228.3906, 27217.2969, 28091.5273,\n",
      "        26818.2402, 26310.3535])\n",
      "y_true      =  tensor([[0.0165, 0.0000, 0.0000, 0.0078, 0.0000, 0.0807, 0.0476, 0.0064]])\n",
      "y_max-x_min =  tensor([263513.5000, 295101.0312, 280331.7188, 291730.0000, 284036.1562,\n",
      "        268619.9062, 271362.6562, 277538.1875])\n",
      "Trash symbol=  tensor([131756.7500, 147550.5156, 140165.8594, 145865.0000, 142018.0781,\n",
      "        134309.9531, 135681.3281, 138769.0938])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    " \n",
    "   result,x_min,x_max,x_true=model(abstract_tensor.unsqueeze(1),add_symbol=False)\n",
    "\n",
    "\n",
    "print(f\"y_min       =  {x_min}\")\n",
    "print(f\"y_max       =  {x_max}\")\n",
    "print(f\"center Ztp  =  {result[0]}\")\n",
    "print(f\"y_true      =  {x_true[:]}\")\n",
    "print(f\"y_max-x_min =  {x_max-x_min}\")\n",
    "print(f\"Trash symbol=  {result[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ResearchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
