{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch   \n",
    "import torch.nn as nn\n",
    "import copy\n",
    "from torch.functional import F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AbstractTorch\n",
    "Ceci est un prototype de moteur d'évaluation s'appuyant sur Torch. L'idée est de surcharger nn.Linear avec des méthodes hybrides, gérant un flux abstrait pour l'évaluation et un flux concret. La simultanéité des deux flux permet d'oberver la position du centre du zonotope par rapport à la valeur réelle de la sortie de la fonction. \n",
    "Ce moteur est moins précis que Saimple car il ne génère pas de nouveaux symboles mais additionne les approximations dans un symbole poubelle. \n",
    "\n",
    "L'implémentation du modèle abstrait comporte une quantité fixe de symboles qui sont gérés comme des épaisseurs de batch. La dernière épaisseur de batch correspond au symbole poubelle, les opération linéaires sont opérées pour cette épaisseur par la valeur absolu de la matrice des poids. \n",
    "\n",
    "Pour l'instant sont implémentées les classes conv2D, Linear , et ReLU. \n",
    "        #TODO implémenter maxpool2D, ... \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée est de tirer profit de la classe nn.Module de Torch en la surchargeant avec des méthodes mixes (flux concret et abstrait). On tire profit de la structure de base\n",
    "de la méthode forward. Au lieu de considérer un batch, on considère une entrée en dimension 0 avec dans les dimensions habituelles du batch des couches de symbole. Une couche (un épaisseur de batch) représente\n",
    "un symbole abstrait. La dernière couche correspond au symbole poubelle. \n",
    "\n",
    "\n",
    "La couche 0 représente le centre du zonotope\n",
    "Les couches suivantes représentent les symboles. Elles sont calculées pour les opération linéaires (Linear et Conv2D) par \n",
    "$$\\textbf{W}(x_\\epsilon)+\\textbf{b}-(\\textbf{W}(0)+\\textbf{b})$$\n",
    "    x[1:]=lin(x_epsilon)-lin(torch.zeros_like(x_epsilon))\n",
    "\n",
    "La derniere couche (bruit poubelle) est calculée par\n",
    "\n",
    "$$\\textbf{|W|}(x_\\epsilon)+\\textbf{b}-(\\textbf{|W|}(0)+\\textbf{b})$$\n",
    "\n",
    "\n",
    "Pour implémenter le tenseur linéaire représentant la valeur absolue, on duplique la couche lin ou conv et on applique la valeur absolue à la matrice de poids. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode abstractTensor permet, à partir d'un tenseur d'origine, de générer un tenseur abstrait. \n",
    "\n",
    "Cette méthode doit être largement enrichie en classe, avec différentes méthodes telles que \n",
    "    add_noise\n",
    "    mul_noise\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstractTensor(tensor: torch.Tensor, alpha : list[float]):\n",
    "    assert len(alpha)==len(tensor.flatten()), \"The length of alpha should be equal to the length of the flatten tensor\"\n",
    "    print(tensor.shape)\n",
    "    \n",
    "    flatten_tensor  = tensor.flatten()\n",
    "    abstract_tensor=[]\n",
    "    abstract_tensor.append(tensor)\n",
    "    for i in range(1,len(flatten_tensor)+1):\n",
    "        abstract_tensor_layer = torch.zeros_like(flatten_tensor)\n",
    "        abstract_tensor_layer[i-1]=alpha[i-1]\n",
    "        abstract_tensor_layer = abstract_tensor_layer.reshape(tensor.shape)\n",
    "        abstract_tensor.append(abstract_tensor_layer)\n",
    "    \n",
    "    abstract_tensor.append(torch.zeros_like(tensor))\n",
    "    abstract_tensor= torch.stack(abstract_tensor)\n",
    "\n",
    "    \n",
    "    return abstract_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractNN(nn.Module):\n",
    "    \n",
    "    def __init__(self,num_symbols: int,num_depth=1,device=torch.device(\"cpu\")):\n",
    "\n",
    "        super(AbstractNN,self).__init__()\n",
    "        num_symbols = num_symbols +2\n",
    "        self.num_symbols = num_symbols\n",
    "        self.num_depth = num_depth\n",
    "        self.device = device\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod    \n",
    "    def abstract_linear(in_features:int,out_features:int,x,x_true,device=torch.device(\"cpu\")):\n",
    "        x =x.unsqueeze(1).to(device)\n",
    "        x_true=x_true.to(device)\n",
    "        lin = nn.Sequential(nn.Flatten(),\n",
    "                            nn.Linear(in_features=in_features, out_features=out_features,device=device))\n",
    "        lin_abs = copy.deepcopy(lin).to(device)\n",
    "        lin_abs[1].weight.data =torch.abs(lin[1].weight.data)\n",
    "     \n",
    "        \n",
    "        x_value = x[0].unsqueeze(1)\n",
    "        x_epsilon= x[1:-1].unsqueeze(1)\n",
    "        x_noise =x[-1].unsqueeze(1)\n",
    "       \n",
    "        x=lin(x)    \n",
    "        x_true = lin(x_true)\n",
    "        x[0]=lin(x_value)\n",
    "        x[1:-1]=lin(x_epsilon)-lin(torch.zeros_like(x_epsilon))\n",
    "        x[-1]=lin_abs(x_noise)-lin_abs(torch.zeros_like(x_noise))\n",
    "        x_min = x[0] - torch.sum(torch.abs(x[1:]),dim=0)\n",
    "        x_max = x[0] + torch.sum(torch.abs(x[1:]),dim=0)\n",
    "        print(x_min.type())\n",
    "        return x,x_min,x_max,x_true\n",
    "    \n",
    "    @staticmethod\n",
    "    def abstract_conv2D(in_channels:int,out_channels:int,kernel_size:int,x,x_true,device=torch.device(\"cpu\")):\n",
    "        x=x.to(device)\n",
    "        x_true = x_true.to(device)\n",
    "        conv = nn.Conv2d(in_channels=in_channels,out_channels=out_channels,kernel_size=kernel_size,device=device)\n",
    "      \n",
    "        conv_abs = copy.deepcopy(conv).to(device)\n",
    "        conv_abs.weight.data = torch.abs(conv.weight.data)\n",
    "     \n",
    "       \n",
    "        x_value = x[0]\n",
    "        x_epsilon= x[1:-1]\n",
    "        x_noise = x[-1]\n",
    "        x=conv(x)\n",
    "        x[0]=conv(x_value)\n",
    "        x_true = conv(x_true)\n",
    "        x[1:-1]=conv(x_epsilon)-conv(torch.zeros_like(x_epsilon).to(device))\n",
    "        x[-1]=conv_abs(x_noise)-conv_abs(torch.zeros_like(x_noise).to(device))\n",
    "        x_min = x[0] - torch.sum(torch.abs(x[1:]),dim=0)\n",
    "        x_max = x[0] + torch.sum(torch.abs(x[1:]),dim=0)\n",
    "        \n",
    "        return x,x_min,x_max,x_true\n",
    "    \n",
    "    @staticmethod\n",
    "    def abstract_relu_conv2D(x,x_min,x_max,x_true,num_symbols:int,add_symbol=False,device=torch.device(\"cpu\")):\n",
    "        num_symbols = len(x)\n",
    "        sgn_min = torch.sign(x_min)\n",
    "        sgn_max = torch.sign(x_max)\n",
    "        sgn = sgn_min+sgn_max\n",
    "        p = x_max/(torch.abs(x_max)+torch.abs(x_min))\n",
    "        q = x_max*(1-p)/2\n",
    "        d = torch.abs(q)\n",
    "        x_true  = nn.ReLU()(x_true)\n",
    "        copy_x_for_approx = x\n",
    "        mask_p = (sgn==0)*1\n",
    "        mask_1 =(sgn==2)*1 + (sgn==1)*1\n",
    "        mask_p = mask_p.unsqueeze(0).expand(num_symbols,-1,-1,-1)\n",
    "        mask_1 = mask_1.unsqueeze(0).expand(num_symbols,-1,-1,-1)\n",
    "        \n",
    "        #approximation of the center 0, (p*x+q) or the value itself \n",
    "        copy_x_for_approx[0]= mask_p[0]*(p*copy_x_for_approx[0]+q)+mask_1[0]*copy_x_for_approx[0]\n",
    "        \n",
    "        #update of the epsilon\n",
    "        copy_x_for_approx[1:-1]=p*mask_p[1:-1]*copy_x_for_approx[1:-1] + mask_1[1:-1]*copy_x_for_approx[1:-1]\n",
    "\n",
    "        #update of the noise symbol -> projection 0, |W|*espilon_noise or new noise if new linear approximation\n",
    "        copy_x_for_approx[-1]=d*mask_p[-1] +copy_x_for_approx[-1]*mask_p[-1] +mask_1[-1]*copy_x_for_approx[-1]\n",
    "\n",
    "        x=copy_x_for_approx\n",
    "        \n",
    "        x_min = x[0] - torch.sum(torch.abs(x[1:]),dim=0)\n",
    "        x_max = x[0] + torch.sum(torch.abs(x[1:]),dim=0)\n",
    "        \n",
    "        if add_symbol:\n",
    "            \"\"\"\n",
    "            new_symbols_indexes =torch.where(x[-1]!=0)\n",
    "\n",
    "\n",
    "            for index,value in enumerate(new_symbols_indexes[0]):\n",
    "            \n",
    "            \n",
    "                x =torch.cat((x,x[-1].unsqueeze(0)),dim=0)\n",
    "                \n",
    "                x[-2]=torch.zeros_like(x[-2])\n",
    "                \n",
    "                x[-2][value]=x[-1][value]\n",
    "            x[-1]=torch.zeros_like(x[-1])\n",
    "            \"\"\"\n",
    "                        \n",
    "            new_eps =torch.where(x[-1]!=0)[0].to(device)\n",
    "            index = torch.arange(len(new_eps)).to(device)\n",
    "            new_eps_batch_shape = x[-1].expand(len(new_eps)+1,-1,-1,-1).shape\n",
    "            new_eps_batch = torch.zeros(new_eps_batch_shape).to(device)\n",
    "            new_eps_batch[index,new_eps]=x[-1][new_eps]\n",
    "\n",
    "            x=x[:-1]\n",
    "\n",
    "            x = torch.cat((x,new_eps_batch),dim=0)            \n",
    "\n",
    "        return x,x_min,x_max,x_true\n",
    "    \n",
    "    @staticmethod\n",
    "    def abstract_relu(x,x_min,x_max,x_true, num_symbols:int,add_symbol=False,device=torch.device(\"cpu\")):\n",
    "        num_symbols = len(x)\n",
    "        if add_symbol:\n",
    "            num_symbols = len(x)\n",
    "        sgn_min = torch.sign(x_min)\n",
    "        sgn_max = torch.sign(x_max)\n",
    "        sgn = sgn_min+sgn_max\n",
    "        p = x_max/(torch.abs(x_max)+torch.abs(x_min))\n",
    "        q = x_max*(1-p)/2\n",
    "        d = torch.abs(q)\n",
    "        x_true  = nn.ReLU()(x_true)\n",
    "        copy_x_for_approx = x\n",
    "\n",
    "        #mask for values that will be approximated by the linear approximation\n",
    "        mask_p = (sgn==0)*1\n",
    "        #mask for the values for those the output is the same as the input (y=x)\n",
    "        mask_1 =(sgn==2)*1+ (sgn==1)*1\n",
    "        #expand the mask to the number of symbols\n",
    "        mask_p = mask_p.unsqueeze(0).expand(num_symbols,-1)\n",
    "        mask_1 = mask_1.unsqueeze(0).expand(num_symbols,-1)\n",
    "        #approximation of the center  \n",
    "        copy_x_for_approx[0]= mask_p[0]*(p*copy_x_for_approx[0]+q)+mask_1[0]*copy_x_for_approx[0]\n",
    "        #uptade of the epsilon\n",
    "        copy_x_for_approx[1:-1]=p*mask_p[1:-1]*copy_x_for_approx[1:-1] + mask_1[1:-1]*copy_x_for_approx[1:-1]\n",
    "        #update of the noise symbol -> projection 0, |W|*espilon_noise or new noise if new linear approximation\n",
    "        copy_x_for_approx[-1]=d*mask_p[-1] +copy_x_for_approx[-1]*mask_p[-1] + mask_1[-1]*copy_x_for_approx[-1]\n",
    "        x=copy_x_for_approx\n",
    "\n",
    "        x_min = x[0] - torch.sum(torch.abs(x[1:]),dim=0)\n",
    "        x_max = x[0] + torch.sum(torch.abs(x[1:]),dim=0)\n",
    "        \n",
    "        if add_symbol:\n",
    "            \"\"\"\n",
    "            new_symbols_indexes =torch.where(x[-1]!=0)\n",
    "\n",
    "\n",
    "            for index,value in enumerate(new_symbols_indexes[0]):\n",
    "            \n",
    "            \n",
    "                x =torch.cat((x,x[-1].unsqueeze(0)),dim=0)\n",
    "                \n",
    "                x[-2]=torch.zeros_like(x[-2])\n",
    "                \n",
    "                x[-2][value]=x[-1][value]\n",
    "            x[-1]=torch.zeros_like(x[-1])\n",
    "            \n",
    "            \"\"\"\n",
    "            new_eps =torch.where(x[-1]!=0)[0].to(device)\n",
    "            \n",
    "            index = torch.arange(len(new_eps)).to(device)\n",
    "            new_eps_batch_shape = x[-1].expand(len(new_eps)+1,-1).shape\n",
    "            new_eps_batch = torch.zeros(new_eps_batch_shape).to(device)\n",
    "            new_eps_batch[index,new_eps]=x[-1][new_eps]\n",
    "\n",
    "            x=x[:-1]\n",
    "\n",
    "            x = torch.cat((x,new_eps_batch),dim=0)\n",
    "\n",
    "        return x,x_min,x_max,x_true\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        \n",
    "        x_true = x\n",
    "        x_true = x_true[0].unsqueeze(0)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "        x,x_min,x_max,x_true = self.abstract_conv2D(self.num_depth,16,3,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = self.abstract_relu_conv2D(x,x_min,x_max,x_true,self.num_symbols,add_symbol=True,device =self.device)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "       \n",
    "        x,x_min,x_max,x_true = self.abstract_conv2D(16,16,3,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = self.abstract_relu_conv2D(x,x_min,x_max,x_true,self.num_symbols,add_symbol=True,device =self.device)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "        x,x_min,x_max,x_true = self.abstract_conv2D(16,32,3,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = self.abstract_relu_conv2D(x,x_min,x_max,x_true,self.num_symbols,add_symbol=True,device =self.device)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "        x,x_min,x_max,x_true = self.abstract_conv2D(32,32,3,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = self.abstract_relu_conv2D(x,x_min,x_max,x_true,self.num_symbols,add_symbol=True,device =self.device)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "        x,x_min,x_max,x_true = self.abstract_linear(86528,6272,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = self.abstract_relu(x,x_min,x_max,x_true,self.num_symbols,add_symbol=True,device =self.device)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "        x,x_min,x_max,x_true = self.abstract_linear(6272,6272,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = self.abstract_relu(x,x_min,x_max,x_true,self.num_symbols,add_symbol=True,device =self.device)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "        x,x_min,x_max,x_true = self.abstract_linear(6272,6272,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = self.abstract_relu(x,x_min,x_max,x_true,self.num_symbols,add_symbol=True,device =self.device)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "        x,x_min,x_max,x_true = self.abstract_linear(6272,6272,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = self.abstract_relu(x,x_min,x_max,x_true,self.num_symbols,add_symbol=True,device =self.device)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "        x,x_min,x_max,x_true = self.abstract_linear(6272,512,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = self.abstract_relu(x,x_min,x_max,x_true,self.num_symbols,add_symbol=True,device =self.device)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "        x,x_min,x_max,x_true = self.abstract_linear(512,256,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = self.abstract_relu(x,x_min,x_max,x_true,self.num_symbols,add_symbol=True,device =self.device)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "\n",
    "        x,x_min,x_max,x_true = self.abstract_linear(256,8,x,x_true,device=self.device)\n",
    "        x,x_min,x_max,x_true = self.abstract_relu(x,x_min,x_max,x_true,self.num_symbols,device =self.device)\n",
    "        print(f\"lenx:{len(x)}\")\n",
    "        return x,x_min,x_max,x_true\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on évalue un modèle généré aléatoirement, composé de 4 couches de convolution et de 5 couches linéaires, chacunes avec une fonction d'activation ReLU\n",
    "L'évaluation se fait sur un tenseur [54,54] généré aléatoirement, qui peut correspondre à une image par exemple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.0586)\n",
      "torch.Size([60, 60])\n",
      "abstract_tensor.shape= torch.Size([3602, 60, 60])\n",
      "abstract_tensor.type= torch.mps.FloatTensor\n",
      "AbstractNN()\n",
      "lenx:3602\n",
      "lenx:3713\n",
      "lenx:3880\n",
      "lenx:4284\n",
      "lenx:4757\n",
      "torch.mps.FloatTensor\n",
      "lenx:5027\n",
      "torch.mps.FloatTensor\n",
      "lenx:5343\n",
      "torch.mps.FloatTensor\n",
      "lenx:5629\n",
      "torch.mps.FloatTensor\n",
      "lenx:5843\n",
      "torch.mps.FloatTensor\n",
      "lenx:5850\n",
      "torch.mps.FloatTensor\n",
      "lenx:5850\n",
      "torch.mps.FloatTensor\n",
      "lenx:5850\n",
      "y_min       =  tensor([0.0335, -0.0000, -0.0000, -0.0000, 0.0158, -0.0000, 0.0226, 0.0274],\n",
      "       device='mps:0')\n",
      "y_max       =  tensor([0.0336, 0.0000, 0.0000, 0.0000, 0.0159, 0.0000, 0.0227, 0.0275],\n",
      "       device='mps:0')\n",
      "center Ztp  =  tensor([0.0335, -0.0000, -0.0000, -0.0000, 0.0158, -0.0000, 0.0227, 0.0274],\n",
      "       device='mps:0')\n",
      "y_true      =  tensor([[0.0335, 0.0000, 0.0000, 0.0000, 0.0158, 0.0000, 0.0227, 0.0274]],\n",
      "       device='mps:0')\n",
      "y_max-x_min =  tensor([6.6265e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9745e-05, 0.0000e+00,\n",
      "        6.7160e-05, 7.2993e-05], device='mps:0')\n",
      "Trash symbol=  tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "!PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0\n",
    "device =torch.device('mps')\n",
    "tensor = torch.randn(60,60)\n",
    "print(torch.max(tensor.flatten()  ))\n",
    "alpha = 0.001*torch.ones_like(tensor.flatten())\n",
    "abstract_tensor = abstractTensor(tensor,alpha).float()\n",
    "\n",
    "print(f\"abstract_tensor.shape= {abstract_tensor.shape}\")\n",
    "abstract_tensor = abstract_tensor.to(device)\n",
    "print(f\"abstract_tensor.type= {abstract_tensor.type()}\")\n",
    "model = AbstractNN(60*60,device=device)\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "\n",
    "with torch.no_grad():\n",
    " \n",
    "   result,x_min,x_max,x_true=model(abstract_tensor.unsqueeze(1))\n",
    "\n",
    "\n",
    "print(f\"y_min       =  {x_min}\")\n",
    "print(f\"y_max       =  {x_max}\")\n",
    "print(f\"center Ztp  =  {result[0]}\")\n",
    "print(f\"y_true      =  {x_true[:]}\")\n",
    "print(f\"y_max-x_min =  {x_max-x_min}\")\n",
    "print(f\"Trash symbol=  {result[-1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3655\n",
      "3602\n"
     ]
    }
   ],
   "source": [
    "print(len(result))\n",
    "print(len(abstract_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on évalue un modèle fictif, l'entrée est une image de 26 sur 26 par 3 épaisseur,avec un symbole associé avec chaque dimension d'entrée (3*26*26)\n",
    "Attention, la dimension de la première couche linéaire doit s'accorder, le code vous renvoiera une erreur (10368 au lieu de 67712)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.2062)\n",
      "torch.Size([3, 26, 26])\n",
      "abstract_tensor.shape= torch.Size([2030, 3, 26, 26])\n",
      "y_min       =  tensor([0.0279, -0.0000, 0.0438, -0.0000, -0.0000, 0.0425, 0.0369, 0.0619])\n",
      "y_max       =  tensor([0.0282, 0.0000, 0.0441, 0.0000, 0.0000, 0.0428, 0.0372, 0.0623])\n",
      "center Ztp  =  tensor([0.0281, -0.0000, 0.0439, -0.0000, -0.0000, 0.0427, 0.0370, 0.0621])\n",
      "y_true      =  tensor([[0.0281, 0.0000, 0.0439, 0.0000, 0.0000, 0.0427, 0.0370, 0.0621]])\n",
      "y_max-x_min =  tensor([0.0003, 0.0000, 0.0004, 0.0000, 0.0000, 0.0004, 0.0003, 0.0004])\n",
      "Trash symbol=  tensor([0.0002, 0.0000, 0.0002, 0.0000, 0.0000, 0.0002, 0.0002, 0.0002])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor = torch.randn(3,26,26)\n",
    "print(torch.max(tensor.flatten()  ))\n",
    "alpha = 0.000005*torch.ones_like(tensor.flatten())\n",
    "abstract_tensor = abstractTensor(tensor,alpha)\n",
    "print(f\"abstract_tensor.shape= {abstract_tensor.shape}\")\n",
    "model = AbstractNN(26*26*3,num_depth=3)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    " \n",
    "   result,x_min,x_max,x_true=model(abstract_tensor)\n",
    "\n",
    "\n",
    "print(f\"y_min       =  {x_min}\")\n",
    "print(f\"y_max       =  {x_max}\")\n",
    "print(f\"center Ztp  =  {result[0]}\")\n",
    "print(f\"y_true      =  {x_true[:]}\")\n",
    "print(f\"y_max-x_min =  {x_max-x_min}\")\n",
    "print(f\"Trash symbol=  {result[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "device =torch.device('mps')\n",
    "tensor = torch.randn(2,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2963)\n",
      "torch.Size([2, 2])\n",
      "torch.FloatTensor\n",
      "result = tensor([[-0.5611, -0.6019, -1.3127,  0.4239,  0.5597],\n",
      "        [-0.2410, -0.2443, -0.2251,  0.1972,  0.2159],\n",
      "        [ 0.0670, -0.1541, -0.1763, -0.0461,  0.0528],\n",
      "        [ 0.1253, -0.1288,  0.1929, -0.0029,  0.0682],\n",
      "        [-0.1605, -0.1294, -0.1256,  0.1114,  0.1824],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]], grad_fn=<CopySlices>)\n",
      "result = tensor([[ 4.5138e-04,  1.1391e-03, -0.0000e+00,  4.2393e-01,  5.5974e-01],\n",
      "        [-6.6451e-03, -1.0174e-02,  0.0000e+00,  1.9718e-01,  2.1587e-01],\n",
      "        [ 1.8461e-03, -6.4185e-03,  0.0000e+00, -4.6076e-02,  5.2821e-02],\n",
      "        [ 3.4554e-03, -5.3646e-03,  0.0000e+00, -2.8602e-03,  6.8199e-02],\n",
      "        [-4.4260e-03, -5.3901e-03,  0.0000e+00,  1.1136e-01,  1.8239e-01],\n",
      "        [ 1.5921e-02,  2.6208e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       grad_fn=<CopySlices>)\n",
      "y_true = tensor([[0.0000, 0.0000, 0.0000, 0.4239, 0.5597]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.max(tensor.flatten()  ))\n",
    "alpha = 0.5*torch.ones_like(tensor.flatten())\n",
    "abstract_tensor = abstractTensor(tensor,alpha).float()\n",
    "result,x_min,x_max,x_true = AbstractNN.abstract_linear(4,5,abstract_tensor,abstract_tensor[0].unsqueeze(0))\n",
    "print(f\"result = {result}\")\n",
    "result,x_min,x_max,x_true = AbstractNN.abstract_relu(result,x_min,x_max,x_true,6,add_symbol=False)\n",
    "print(f\"result = {result}\")\n",
    "print(f\"y_true = {x_true}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sie =result.size()\n",
    "sie[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/52/k6pzm88n5_xdgm1mjpjcgnc80000gn/T/ipykernel_52911/1469605289.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(test[0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 3, 4])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = torch.tensor(test[0])\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_eps =torch.where(x[-1]!=0)\n",
    "index = torch.arange(len(new_eps[0]))\n",
    "new_eps_batch = result[-1].expand(len(new_eps[0])+1,-1).shape\n",
    "new_eps_batch = torch.zeros(new_eps_batch)\n",
    "new_eps_batch[index,new_eps[0]]=result[-1][new_eps[0]]\n",
    "\n",
    "x=x[:-1]\n",
    "\n",
    "x = torch.cat((x,new_eps_batch),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.5138e-04,  1.1391e-03, -0.0000e+00,  4.2393e-01,  5.5974e-01],\n",
       "        [-6.6451e-03, -1.0174e-02,  0.0000e+00,  1.9718e-01,  2.1587e-01],\n",
       "        [ 1.8461e-03, -6.4185e-03,  0.0000e+00, -4.6076e-02,  5.2821e-02],\n",
       "        [ 3.4554e-03, -5.3646e-03,  0.0000e+00, -2.8602e-03,  6.8199e-02],\n",
       "        [-4.4260e-03, -5.3901e-03,  0.0000e+00,  1.1136e-01,  1.8239e-01],\n",
       "        [ 1.5921e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  2.6208e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for index,value in enumerate(test[0]):\n",
    "   \n",
    "   \n",
    "    result =torch.cat((result,result[-1].unsqueeze(0)),dim=0)\n",
    "    \n",
    "    result[-2]=torch.zeros_like(result[-2])\n",
    "    \n",
    "    result[-2][value]=result[-1][value]\n",
    "result[-1]=torch.zeros_like(result[-1])\n",
    "\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0.],\n",
      "        [0., 0., 3., 0., 0., 0.],\n",
      "        [0., 0., 0., 4., 0., 0.],\n",
      "        [0., 0., 0., 0., 5., 0.],\n",
      "        [0., 0., 0., 0., 0., 6.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Supposons que votre tenseur d'origine soit x\n",
    "x = torch.tensor([1, 2, 0, 0, 3, 0, 4, 5, 0, 6])\n",
    "\n",
    "# Créer un masque pour les valeurs non nulles dans x\n",
    "mask = (x != 0).float()\n",
    "\n",
    "# Nombre de valeurs non nulles\n",
    "num_non_zero = mask.sum().int().item()\n",
    "\n",
    "# Créer un tenseur identité de la bonne taille\n",
    "identity = torch.eye(num_non_zero)\n",
    "\n",
    "# Appliquer le masque aux valeurs non nulles\n",
    "masked_values = x[mask.bool()]\n",
    "\n",
    "# Créer le nouveau tenseur en multipliant le tenseur identité par les valeurs non nulles\n",
    "new_tensor = identity * masked_values.unsqueeze(1)\n",
    "\n",
    "print(new_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0, 0, 0, 0],\n",
      "        [0, 2, 0, 0, 0, 0],\n",
      "        [0, 0, 3, 0, 0, 0],\n",
      "        [0, 0, 0, 4, 0, 0],\n",
      "        [0, 0, 0, 0, 5, 0],\n",
      "        [0, 0, 0, 0, 0, 6]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Supposons que votre tenseur d'origine soit x\n",
    "x = torch.tensor([1, 2, 0, 0, 3, 0, 4, 5, 0, 6])\n",
    "\n",
    "# Créer un masque pour les valeurs non nulles dans x\n",
    "mask = (x != 0)\n",
    "\n",
    "# Extraire les valeurs non nulles de x\n",
    "non_zero_values = x[mask]\n",
    "\n",
    "# Créer un tenseur diagonal avec les valeurs non nulles\n",
    "diagonal_tensor = torch.diag_embed(non_zero_values)\n",
    "\n",
    "# Créer un tenseur de zéros de la taille souhaitée\n",
    "zeros_tensor = torch.zeros_like(diagonal_tensor)\n",
    "\n",
    "# Ajouter les deux tenseurs pour obtenir le résultat final\n",
    "result_tensor = diagonal_tensor + zeros_tensor\n",
    "\n",
    "print(result_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.zeros(4,10)\n",
    "index = torch.tensor([0,1,2,3])\n",
    "value = torch.tensor([4,5,7,2])\n",
    "test[index,value]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ResearchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
